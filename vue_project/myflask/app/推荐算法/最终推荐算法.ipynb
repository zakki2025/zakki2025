{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：协同过滤，基于用户相似度为用户推荐菜品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating different algorithms...\n",
      "\n",
      "Evaluating KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Evaluating KNNWithMeans...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Evaluating KNNWithZScore...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Evaluating SVD...\n",
      "\n",
      "Evaluating SVDpp...\n",
      "\n",
      "Evaluating NMF...\n",
      "\n",
      "Algorithm Comparison Results:\n",
      "KNNBasic:\n",
      "  RMSE: 1.1052\n",
      "  MAE: 0.8028\n",
      "KNNWithMeans:\n",
      "  RMSE: 1.0508\n",
      "  MAE: 0.7407\n",
      "KNNWithZScore:\n",
      "  RMSE: 1.0688\n",
      "  MAE: 0.7491\n",
      "SVD:\n",
      "  RMSE: 0.9760\n",
      "  MAE: 0.7445\n",
      "SVDpp:\n",
      "  RMSE: 0.9720\n",
      "  MAE: 0.7295\n",
      "NMF:\n",
      "  RMSE: 1.1144\n",
      "  MAE: 0.8533\n",
      "\n",
      "Optimizing SVD parameters...\n",
      "\n",
      "Best SVD parameters: {'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "Best RMSE: 0.9594\n",
      "\n",
      "Training final model with optimized parameters...\n",
      "RMSE: 0.9608\n",
      "MAE:  0.7190\n",
      "Final Model RMSE: 0.9608\n",
      "Final Model MAE: 0.7190\n",
      "\n",
      "Generating recommendations for user: A2WOH395IHGS0T\n",
      "\n",
      "Top 5 Recommended Meals:\n",
      "1. 白灼虾 (海鲜) - ¥29\n",
      "   Predicted Rating: 5\n",
      "2. 番茄土豆丝 (素菜) - ¥10\n",
      "   Predicted Rating: 5\n",
      "3. 烤排骨 (猪肉) - ¥29\n",
      "   Predicted Rating: 5\n",
      "4. 凉拌黑木耳 (素菜) - ¥10\n",
      "   Predicted Rating: 5\n",
      "5. 素豆腐包 (豆制品) - ¥10\n",
      "   Predicted Rating: 5\n",
      "\n",
      "Dataset Statistics:\n",
      "Total number of users: 5130\n",
      "Total number of meals: 1685\n",
      "Total number of ratings: 38384\n",
      "Rating sparsity: 99.56%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from surprise import Dataset, Reader  \n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate  \n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, SVD, SVDpp, NMF  \n",
    "from surprise import accuracy  \n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# Load and prepare data  \n",
    "file_path = 'MealRating.csv'  \n",
    "df = pd.read_csv(file_path)  \n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')  \n",
    "data = df[['UserID', 'MealID', 'Rating']].dropna()  \n",
    "\n",
    "# Create Surprise reader and dataset  \n",
    "reader = Reader(rating_scale=(1, 5))  \n",
    "dataset = Dataset.load_from_df(data, reader)  \n",
    "\n",
    "# Step 1: Compare different algorithms  \n",
    "def evaluate_algorithms(data):  \n",
    "    algorithms = {  \n",
    "        'KNNBasic': KNNBasic(),  \n",
    "        'KNNWithMeans': KNNWithMeans(),  \n",
    "        'KNNWithZScore': KNNWithZScore(),  \n",
    "        'SVD': SVD(),  \n",
    "        'SVDpp': SVDpp(),  \n",
    "        'NMF': NMF()  \n",
    "    }  \n",
    "    \n",
    "    results = {}  \n",
    "    for name, algo in algorithms.items():  \n",
    "        print(f\"\\nEvaluating {name}...\")  \n",
    "        cv_results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=False)  \n",
    "        results[name] = {  \n",
    "            'RMSE': cv_results['test_rmse'].mean(),  \n",
    "            'MAE': cv_results['test_mae'].mean()  \n",
    "        }  \n",
    "    return results  \n",
    "\n",
    "# Step 2: Parameter optimization for the best algorithm  \n",
    "def optimize_svd_params(data):  \n",
    "    param_grid = {  \n",
    "        'n_epochs': [20, 30, 40],  \n",
    "        'lr_all': [0.005, 0.01],  \n",
    "        'reg_all': [0.02, 0.1, 0.4]  \n",
    "    }  \n",
    "    \n",
    "    gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)  \n",
    "    gs.fit(data)  \n",
    "    \n",
    "    return gs.best_score['rmse'], gs.best_params['rmse']  \n",
    "\n",
    "# Step 3: Train final model with best parameters  \n",
    "def train_final_model(data, best_params):  \n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)  \n",
    "    \n",
    "    algo = SVD(  \n",
    "        n_epochs=best_params['n_epochs'],  \n",
    "        lr_all=best_params['lr_all'],  \n",
    "        reg_all=best_params['reg_all']  \n",
    "    )  \n",
    "    \n",
    "    algo.fit(trainset)  \n",
    "    predictions = algo.test(testset)  \n",
    "    return algo, accuracy.rmse(predictions), accuracy.mae(predictions)  \n",
    "\n",
    "def get_top_n_recommendations(algo, user_id, n=5):  \n",
    "    \"\"\"Get top N recommendations for a specific user.\"\"\"  \n",
    "    # Get items the user hasn't rated  \n",
    "    user_ratings = df[df['UserID'] == user_id]['MealID'].unique()  \n",
    "    all_items = df['MealID'].unique()  \n",
    "    items_to_predict = np.setdiff1d(all_items, user_ratings)  \n",
    "    \n",
    "    # Get predictions  \n",
    "    predictions = []  \n",
    "    for item_id in items_to_predict:  \n",
    "        pred = algo.predict(user_id, item_id)  \n",
    "        predictions.append((item_id, pred.est))  \n",
    "    \n",
    "    # Sort predictions by estimated rating  \n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)  \n",
    "    \n",
    "    # Get top N  \n",
    "    top_n = predictions[:n]  \n",
    "    \n",
    "    # Get meal details for recommendations  \n",
    "    recommended_meals = []  \n",
    "    for meal_id, pred_rating in top_n:  \n",
    "        meal_info = df[df['MealID'] == meal_id].iloc[0]  \n",
    "        recommended_meals.append({  \n",
    "            'MealID': meal_id,  \n",
    "            'MealName': meal_info['mealName'],  \n",
    "            'MealType': meal_info['mealType'],  \n",
    "            'MealPrice': meal_info['mealPrice'],  \n",
    "            'PredictedRating': round(pred_rating, 2)  \n",
    "        })  \n",
    "    \n",
    "    return recommended_meals  \n",
    "\n",
    "# Run the optimization process  \n",
    "print(\"Evaluating different algorithms...\")  \n",
    "results = evaluate_algorithms(dataset)  \n",
    "\n",
    "# Print algorithm comparison results  \n",
    "print(\"\\nAlgorithm Comparison Results:\")  \n",
    "for algo, metrics in results.items():  \n",
    "    print(f\"{algo}:\")  \n",
    "    print(f\"  RMSE: {metrics['RMSE']:.4f}\")  \n",
    "    print(f\"  MAE: {metrics['MAE']:.4f}\")  \n",
    "\n",
    "# Optimize SVD parameters  \n",
    "print(\"\\nOptimizing SVD parameters...\")  \n",
    "best_rmse, best_params = optimize_svd_params(dataset)  \n",
    "print(f\"\\nBest SVD parameters: {best_params}\")  \n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")  \n",
    "\n",
    "# Train final model  \n",
    "print(\"\\nTraining final model with optimized parameters...\")  \n",
    "final_algo, final_rmse, final_mae = train_final_model(dataset, best_params)  \n",
    "print(f\"Final Model RMSE: {final_rmse:.4f}\")  \n",
    "print(f\"Final Model MAE: {final_mae:.4f}\")  \n",
    "\n",
    "# Generate recommendations for a sample user  \n",
    "test_user = df['UserID'].iloc[0]  \n",
    "print(f\"\\nGenerating recommendations for user: {test_user}\")  \n",
    "recommendations = get_top_n_recommendations(final_algo, test_user, n=5)  \n",
    "\n",
    "print(\"\\nTop 5 Recommended Meals:\")  \n",
    "for i, rec in enumerate(recommendations, 1):  \n",
    "    print(f\"{i}. {rec['MealName']} ({rec['MealType']}) - ¥{rec['MealPrice']}\")  \n",
    "    print(f\"   Predicted Rating: {rec['PredictedRating']}\")  \n",
    "\n",
    "# Print dataset statistics  \n",
    "print(\"\\nDataset Statistics:\")  \n",
    "print(f\"Total number of users: {len(df['UserID'].unique())}\")  \n",
    "print(f\"Total number of meals: {len(df['MealID'].unique())}\")  \n",
    "print(f\"Total number of ratings: {len(df)}\")  \n",
    "print(f\"Rating sparsity: {(1 - len(df)/(len(df['UserID'].unique())*len(df['MealID'].unique())))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终推荐度最高的5个店铺及其各项得分：\n",
      "                        店铺名称   菜品相似度得分  场景相似度得分  关注点相似度得分  总体评分       推荐分\n",
      "3              洪鸭纪干锅鸭头(定福庄店)  9.299961        1         1   0.5  4.669985\n",
      "203                 Ditto儿咖啡  8.495572        1         1   0.5  4.348229\n",
      "257      锅里满口香锅贴水饺家常菜(传媒大学店)  8.258291        1         1   0.0  4.203316\n",
      "18   草原黑森林碳烤羊腿·定福庄扛把子(朝阳北路店)  7.928850        1         1   1.0  4.171540\n",
      "667              泉州面线糊(财满街店)  8.106827        1         1   0.0  4.142731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 加载预训练的SBERT模型\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 读取店铺信息并转换数值列为合适的类型\n",
    "file_path_shop_info = '店铺标签_更新2.xlsx'\n",
    "df_shop_info = pd.read_excel(file_path_shop_info)\n",
    "\n",
    "# 确保数值列被正确解析为浮点数或整数，处理可能存在的缺失值\n",
    "numeric_columns = ['口味分', '服务分', '环境分', '总分']\n",
    "df_shop_info[numeric_columns] = df_shop_info[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 读取菜品描述数据\n",
    "file_path_meal_descriptions = '阿里云菜品描述.xlsx'\n",
    "df_meal_descriptions = pd.read_excel(file_path_meal_descriptions)\n",
    "\n",
    "# 创建一个映射字典，用于快速查找菜品描述\n",
    "meal_description_map = df_meal_descriptions.set_index('菜品名称')['菜品描述'].to_dict()\n",
    "\n",
    "# 定义一个函数来获取菜品描述\n",
    "def get_meal_description(meal_name):\n",
    "    return meal_description_map.get(meal_name, \"无法找到该菜品的描述\")\n",
    "\n",
    "# 获取推荐菜品的描述并构建用户输入信息\n",
    "user_food_descriptions = [get_meal_description(rec['MealName']) for rec in recommendations]\n",
    "\n",
    "# 用户输入信息中的其他部分保持不变\n",
    "user_meal_scene = \"朋友聚会\"  # 例如：家庭聚餐、情侣约会等\n",
    "user_focus_point = \"服务\"  # 关注点（口味/服务/环境）\n",
    "\n",
    "\n",
    "# 第一步：算菜品相似度\n",
    "def calc_food_similarity(shop_description, user_description):\n",
    "    if pd.isna(shop_description):  # 检查是否为NaN\n",
    "        return 0.0\n",
    "    shop_embedding = model.encode(shop_description, convert_to_tensor=True)\n",
    "    user_embedding = model.encode(user_description, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(shop_embedding, user_embedding)\n",
    "    return float(cosine_scores[0]) * 10  # 转换为10分制\n",
    "\n",
    "# 第二步：算场景相似度\n",
    "def calc_scene_similarity(scene_tags, user_scene):\n",
    "    if pd.notna(scene_tags) and user_scene in scene_tags:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 第三步：算关注点相似度\n",
    "def calc_focus_similarity(focus_score, focus_point):\n",
    "    if pd.notna(focus_score) and focus_score > 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 第四步：算总体得分\n",
    "def calc_overall_score(total_score):\n",
    "    if pd.isna(total_score):\n",
    "        return 0\n",
    "    elif total_score > 4.5:\n",
    "        return 1\n",
    "    elif total_score > 4.3:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 计算每个描述与所有店铺的【菜品相似度得分】，并保留前20个店铺\n",
    "top_shops_per_description = {}\n",
    "for description in user_food_descriptions:\n",
    "    df_shop_info['菜品相似度得分'] = df_shop_info['店铺描述'].apply(lambda x: calc_food_similarity(x, description))\n",
    "    top_20_shops = df_shop_info.nlargest(20, '菜品相似度得分').copy()\n",
    "    top_shops_per_description[description] = top_20_shops\n",
    "\n",
    "# 对每个描述中的20个店铺进行后续计算，并选出推荐分最高的店铺\n",
    "recommended_shops = []\n",
    "for description, top_20_shops in top_shops_per_description.items():\n",
    "    # 对这20个店铺进行第二三四五步的其他相似度计算\n",
    "    top_20_shops['场景相似度得分'] = top_20_shops.apply(lambda row: calc_scene_similarity(str(row['场景标签']), user_meal_scene), axis=1)\n",
    "    top_20_shops['关注点相似度得分'] = top_20_shops.apply(lambda row: calc_focus_similarity(row[user_focus_point + '分'], user_focus_point), axis=1)\n",
    "    top_20_shops['总体评分'] = top_20_shops.apply(lambda row: calc_overall_score(row['总分']), axis=1)\n",
    "    \n",
    "    # 计算综合推荐分\n",
    "    top_20_shops['推荐分'] = (\n",
    "        top_20_shops['菜品相似度得分'] * 0.4 +\n",
    "        top_20_shops['场景相似度得分'] * 0.4 +\n",
    "        top_20_shops['关注点相似度得分'] * 0.5 +\n",
    "        top_20_shops['总体评分'] * 0.1\n",
    "    )\n",
    "    \n",
    "    # 从这20个店铺中选出推荐分最高的一个店铺\n",
    "    best_shop = top_20_shops.nlargest(1, '推荐分')\n",
    "    recommended_shops.append(best_shop[['店铺名称', '菜品相似度得分', '场景相似度得分', '关注点相似度得分', '总体评分', '推荐分']])\n",
    "\n",
    "# 合并推荐结果并去重，选取最终推荐的5个店铺\n",
    "final_recommendations = pd.concat(recommended_shops).drop_duplicates(subset=['店铺名称']).nlargest(5, '推荐分')\n",
    "\n",
    "print(\"最终推荐度最高的5个店铺及其各项得分：\")\n",
    "print(final_recommendations[['店铺名称', '菜品相似度得分', '场景相似度得分', '关注点相似度得分', '总体评分', '推荐分']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
